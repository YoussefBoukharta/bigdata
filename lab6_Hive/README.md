# Lab 6 ‚Äî Apache Hive & Data Warehousing

üìÑ **Documentation compl√®te disponible dans le fichier "YOUSSEF_BOUKHARTA_TP6_HIVE.pdf"**

## üéØ Objectifs du TP

Ce laboratoire vise √† :
- ‚úÖ **Installation d'Apache Hive** : D√©ploiement via Docker avec HiveServer2
- ‚úÖ **Premi√®re utilisation d'Apache Hive** : Manipulation de Beeline et interface JDBC
- ‚úÖ **R√©aliser des requ√™tes analytiques** : Jointures, agr√©gations, partitionnement et bucketing

### √Ä propos d'Apache Hive

Apache Hive est un **software datawarehouse** con√ßu pour lire, √©crire et g√©rer de grands ensembles de donn√©es extraits du syst√®me de fichiers distribu√© d'Apache Hadoop (HDFS).

**Caract√©ristiques principales :**
- üìä Ne s'agit pas d'une base de donn√©es compl√®te
- üóÑÔ∏è Stocke uniquement les **m√©tadonn√©es** (les donn√©es sont dans HDFS)
- üîÑ Chaque requ√™te est convertie en code **MapReduce**
- üìà Utilisable comme syst√®me **OLAP** (Online Analytical Processing)
- üîå Fourni avec **HiveServer2** et son client JDBC **Beeline**

## üê≥ Installation Apache Hive

### 1Ô∏è‚É£ Pull de l'image Docker

```bash
docker pull apache/hive:4.0.0-alpha-2
```

**Source :** [Docker Hub - Apache Hive](https://hub.docker.com/r/apache/hive/tags)

### 2Ô∏è‚É£ Lancement du conteneur HiveServer2

```bash
docker run -v C:\Users\ahmed\hadoop_project:/shared_volume -d -p 10000:10000 -p 10002:10002 -p 9083:9083 --env SERVICE_NAME=hiveserver2 --name hiveserver2-standalone apache/hive:4.0.0-alpha-2
```

**Configuration :**
- **Port 10000** : HiveServer2 (connexion JDBC)
- **Port 10002** : Interface Web HiveServer2
- **Port 9083** : Metastore Service
- **Metastore** : Derby embedded (configuration rapide)

### 3Ô∏è‚É£ Acc√®s √† l'interface Web

Ouvrez votre navigateur √† l'adresse : **http://localhost:10002**

### 4Ô∏è‚É£ Premi√®re utilisation de Beeline

#### Acc√©der au shell du conteneur
```bash
docker exec -it hiveserver2-standalone bash
```

#### V√©rifier HDFS
```bash
hadoop fs -ls
```

#### Visualiser la configuration Hive
```bash
cat /opt/hive/conf/hive-site.xml
```

#### Connexion √† Beeline
```bash
beeline -u jdbc:hive2://localhost:10000 -n scott -p tiger
```

**Credentials par d√©faut :**
- **Username** : `scott`
- **Password** : `tiger`

#### Afficher les bases de donn√©es
```sql
SHOW DATABASES;
```

## üîß Pr√©requis Techniques

### Configuration de l'Environnement

**R√©pertoire de donn√©es (h√¥te) :** `C:\Users\ahmed\hadoop_project\hive_data`

**Fichiers requis :**
- `clients.txt`
- `hotels.txt`
- `reservations.txt`

**Conteneur Hive :** Instance `hiveserver2-standalone` avec montage du volume h√¥te sur `/shared_volume`

### V√©rifications Pr√©alables

‚úÖ Assurez-vous que tous les fichiers de donn√©es sont pr√©sents dans le r√©pertoire h√¥te  
‚úÖ V√©rifiez le montage correct du volume dans le conteneur  
‚úÖ Confirmez la disponibilit√© de HiveServer2 sur le port 10000  
‚úÖ HDFS doit √™tre op√©rationnel dans le conteneur

## üìÅ Structure du Projet

```
lab6_Hive/
‚îú‚îÄ‚îÄ Creation.hql       # Sch√©mas et d√©finitions de tables
‚îú‚îÄ‚îÄ Loading.hql        # Scripts de chargement des donn√©es
‚îú‚îÄ‚îÄ Queries.hql        # Requ√™tes analytiques
‚îú‚îÄ‚îÄ clients.txt        # Donn√©es clients
‚îú‚îÄ‚îÄ hotels.txt         # Donn√©es h√¥tels
‚îú‚îÄ‚îÄ reservations.txt   # Donn√©es r√©servations
‚îî‚îÄ‚îÄ README.md          # Ce fichier
```

## üìä Cas d'√âtude : Analyse de R√©servations d'H√¥tels

Ce TP travaille sur un ensemble de donn√©es concernant les **r√©servations d'h√¥tels**. L'objectif est de manipuler, analyser et extraire des informations pertinentes sur les clients, les h√¥tels et leurs r√©servations.

**Donn√©es disponibles dans trois fichiers :**
1. **clients.txt** : Informations des clients (ID, nom, email, t√©l√©phone)
2. **hotels.txt** : Informations des h√¥tels (ID, nom, √©toiles, ville)
3. **reservations.txt** : R√©servations (ID, client_id, hotel_id, dates, prix)

## üöÄ Ex√©cution des Scripts HiveQL

### ‚ö†Ô∏è S√©quence d'Ex√©cution (Ordre Obligatoire)

Les scripts doivent √™tre ex√©cut√©s **dans l'ordre** suivant pour reproduire le traitement complet :

### 1Ô∏è‚É£ Cr√©ation des Sch√©mas et Tables (`Creation.hql`)

```bash
docker exec -it hiveserver2-standalone bash -c "beeline -u 'jdbc:hive2://localhost:10000' -n scott -p tiger -f /shared_volume/lab6_hive/Creation.hql"
```

**Fonctionnalit√©s :**
- ‚ú® Cr√©ation de la base de donn√©es `hotel_booking`
- üìã D√©finition des tables externes et manag√©es
- üîÑ Configuration du partitionnement dynamique
- ‚ö° Mise en place du bucketing pour optimisation
- ‚öôÔ∏è Activation des propri√©t√©s Hive pour partitions et buckets

**Tables cr√©√©es :**
- `clients` - Table des clients (TEXTFILE)
- `hotels` - Table des h√¥tels (TEXTFILE)
- `raw_reservations` - Table de staging pour r√©servations
- `reservations` - Table partitionn√©e par `date_debut`
- `hotels_partitioned` - Table partitionn√©e par `ville`
- `reservations_bucketed` - Table bucketed par `client_id` (4 buckets)

**V√©rification :**
```bash
hadoop fs -ls /opt/hive/data/warehouse
```
Vous remarquerez la cr√©ation du r√©pertoire `hotel_booking.db`.

---

### 2Ô∏è‚É£ Chargement des Donn√©es (`Loading.hql`)

```bash
docker exec -it hiveserver2-standalone bash -c "beeline -u 'jdbc:hive2://localhost:10000' -n scott -p tiger -f /shared_volume/lab6_hive/Loading.hql"
```

**‚ö†Ô∏è IMPORTANT :** Avant d'ex√©cuter cette √©tape, copiez tous les fichiers `.txt` dans `C:\Users\ahmed\hadoop_project\hive_data`.

**Actions effectu√©es :**
- üì• Chargement avec `LOAD DATA LOCAL INPATH` depuis `/shared_volume/hive_data/`
- üóÇÔ∏è Population des tables partitionn√©es (insertion dynamique)
- üî¢ Chargement dans les buckets avec `DISTRIBUTE BY client_id`
- ‚úÖ V√©rifications de l'int√©grit√© des donn√©es (`SHOW PARTITIONS`, `COUNT(*)`)

**V√©rification :**
```bash
hadoop fs -ls /opt/hive/data/warehouse/hotel_booking.db/
```
Vous remarquerez les sous-r√©pertoires pour les partitions (ex: `date_debut=2024-01-15/`) et les buckets.

---

### 3Ô∏è‚É£ Requ√™tes Analytiques (`Queries.hql`)

```bash
docker exec -it hiveserver2-standalone bash -c "beeline -u 'jdbc:hive2://localhost:10000' -n scott -p tiger -f /shared_volume/lab6_hive/Queries.hql"
```

**Analyses r√©alis√©es :**

#### 5Ô∏è‚É£ Requ√™tes Simples
- Lister tous les clients
- Lister tous les h√¥tels √† Paris
- Lister toutes les r√©servations avec informations compl√®tes (clients + h√¥tels)

#### 6Ô∏è‚É£ Requ√™tes avec Jointures
- üìä **Nombre de r√©servations par client** 
- üõèÔ∏è **Clients ayant r√©serv√© plus de 2 nuit√©es** 
- üè® **H√¥tels r√©serv√©s par chaque client** 
- üìà **H√¥tels avec plus d'une r√©servation** 
- ‚ùå **H√¥tels sans r√©servation** 

#### 7Ô∏è‚É£ Requ√™tes Imbriqu√©es (Subqueries)
- üëë **Clients ayant r√©serv√© un h√¥tel > 4 √©toiles** 
- üí∞ **Total des revenus g√©n√©r√©s par chaque h√¥tel** 

#### 8Ô∏è‚É£ Agr√©gations avec Partitions/Buckets
- üåÜ **Revenus totaux par ville** (utilise tables partitionn√©es)
- üìâ **Nombre de r√©servations par client** (utilise tables bucketed)

#### 9Ô∏è‚É£ Nettoyage et Suppression
- Commandes DROP pour supprimer les tables et la base de donn√©es (comment√©es par d√©faut)

## üìä R√©sultats & Validation

Le document PDF **"YOUSSEF_BOUKHARTA_TP6_HIVE.pdf"** pr√©sente les r√©sultats en captures d'√©cran et contient :

‚úÖ Captures d'√©cran des r√©sultats de chaque requ√™te  
‚è±Ô∏è M√©triques de performance (temps d'ex√©cution)  
üîç Analyse des plans d'ex√©cution (EXPLAIN)  
‚ö° Validation des optimisations appliqu√©es (partitionnement, bucketing)  
üìÅ Exploration de la structure HDFS (`/opt/hive/data/warehouse/hotel_booking.db/`)

## üí° Notes Techniques

### Optimisations Impl√©ment√©es

#### üóÇÔ∏è Partitionnement
- D√©coupage logique des tables par colonnes cl√©s
- Am√©lioration des performances pour les requ√™tes filtr√©es
- R√©duction du volume de donn√©es scann√©es

**Exemple :**
```sql
PARTITIONED BY (date_debut STRING)
PARTITIONED BY (ville STRING)
```

#### üî¢ Bucketing (Clustering)
- Distribution uniforme des donn√©es dans des fichiers
- Optimisation des jointures (map-side joins)
- Am√©lioration du sampling et de l'√©chantillonnage

**Exemple :**
```sql
CLUSTERED BY (client_id) INTO 4 BUCKETS
```

### Bonnes Pratiques

#### üìù Pr√©paration des Donn√©es
‚ö†Ô∏è **CRITIQUE : Supprimer les en-t√™tes CSV avant le chargement**  
```bash
# Exemple de preprocessing (si n√©cessaire)
tail -n +2 clients.txt > clients_clean.txt
```
Alternative : Utiliser `TBLPROPERTIES ("skip.header.line.count"="1")`
- V√©rifier l'encodage des fichiers (UTF-8 recommand√©)
- Valider les d√©limiteurs de champs (virgule par d√©faut)
- S'assurer que les fichiers sont accessibles dans `/shared_volume/hive_data/`

#### üóÑÔ∏è Gestion des M√©tadonn√©es
- Les **tables externes** pr√©servent les donn√©es sources apr√®s suppression
- Les **tables manag√©es** (internes) suppriment les donn√©es avec `DROP TABLE`
- Utiliser `MSCK REPAIR TABLE` pour synchroniser les partitions

#### ‚ö° Performance
```sql
-- Activer la vectorisation
SET hive.vectorized.execution.enabled = true;

-- Optimiser les jointures
SET hive.auto.convert.join = true;

-- Configuration pour partitions dynamiques
SET hive.exec.dynamic.partition = true;
SET hive.exec.dynamic.partition.mode = nonstrict;

-- Configuration pour bucketing
SET hive.enforce.bucketing = true;
```

**Recommandations :**
- Utiliser le format **ORC** ou **Parquet** pour les grandes volum√©tries
- Privil√©gier les partitions pour les colonnes √† faible cardinalit√©
- Optimiser le nombre de buckets en fonction du volume de donn√©es

### üîß Commandes Utiles

#### Se connecter √† Beeline manuellement
```bash
docker exec -it hiveserver2-standalone bash
beeline -u jdbc:hive2://localhost:10000 -n scott -p tiger
```

#### V√©rifier les partitions
```sql
SHOW PARTITIONS reservations;
SHOW PARTITIONS hotels_partitioned;
```

#### Compter les enregistrements
```sql
SELECT COUNT(*) AS cnt_clients FROM clients;
SELECT COUNT(*) AS cnt_hotels FROM hotels;
SELECT COUNT(*) AS cnt_reservations FROM reservations;
```

#### Explorer la structure HDFS
```bash
# Dans le conteneur
hadoop fs -ls /opt/hive/data/warehouse
hadoop fs -ls /opt/hive/data/warehouse/hotel_booking.db/
hadoop fs -ls /opt/hive/data/warehouse/hotel_booking.db/reservations/
```

#### Analyser le plan d'ex√©cution
```sql
EXPLAIN SELECT * FROM reservations WHERE date_debut = '2024-01-15';
EXPLAIN SELECT h.ville, SUM(r.prix_total) FROM reservations r 
        JOIN hotels h ON r.hotel_id = h.hotel_id 
        GROUP BY h.ville;
```

## üßπ Nettoyage (Optionnel)

Pour supprimer toutes les tables et la base de donn√©es :

```sql
DROP TABLE IF EXISTS reservations_bucketed;
DROP TABLE IF EXISTS reservations;
DROP TABLE IF EXISTS raw_reservations;
DROP TABLE IF EXISTS hotels_partitioned;
DROP TABLE IF EXISTS hotels;
DROP TABLE IF EXISTS clients;
DROP DATABASE IF EXISTS hotel_booking CASCADE;
```

## üìù Organisation du Code

Le traitement est organis√© en **trois scripts HiveQL distincts** :

| Script | Description | Responsabilit√© |
|--------|-------------|----------------|
| **Creation.hql** | Cr√©ation de sch√©mas | Base de donn√©es, tables, partitions, buckets |
| **Loading.hql** | Chargement de donn√©es | LOAD DATA, INSERT INTO, v√©rifications |
| **Queries.hql** | Requ√™tes analytiques | Jointures, agr√©gations, requ√™tes imbriqu√©es |

**Ordre d'ex√©cution obligatoire :** `Creation.hql` ‚Üí `Loading.hql` ‚Üí `Queries.hql`

## üéì Comp√©tences D√©velopp√©es

- ‚úÖ Installation et configuration d'Apache Hive avec Docker
- ‚úÖ Manipulation de Beeline (client JDBC)
- ‚úÖ Cr√©ation de tables avec partitionnement et bucketing
- ‚úÖ Chargement de donn√©es en masse (LOAD DATA)
- ‚úÖ Requ√™tes SQL complexes (jointures, agr√©gations, subqueries)
- ‚úÖ Optimisation des performances (partitions, buckets)
- ‚úÖ Analyse de donn√©es avec un syst√®me OLAP
- ‚úÖ Compr√©hension de l'architecture Hive/HDFS/MapReduce

## üìö Ressources Compl√©mentaires

- [Documentation Apache Hive](https://hive.apache.org/)
- [LanguageManual HiveQL](https://cwiki.apache.org/confluence/display/Hive/LanguageManual)
- [Hive Performance Tuning](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Optimization)
- [Docker Hub - Apache Hive](https://hub.docker.com/r/apache/hive)

---

**Auteur :** Youssef Boukharta  